{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit (system)"
  },
  "interpreter": {
   "hash": "b8d2074e4faf2252ee9df1d81cd02b8b35b335ee64055a901d26eb8d41a6f396"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "__author__ = \"Alina Molnar\"\r\n",
    "__copyright__ = \"Copyright (C) 2020-2021 Alina Molnar\"\r\n",
    "__license__ = \"CC BY-NC\"\r\n",
    "__version__ = \"1.0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 1. IMPORT LIBRARIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\r\n",
    "from math import ceil\r\n",
    "from pathlib import PureWindowsPath\r\n",
    "\r\n",
    "import h2o\r\n",
    "import IPython\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from h2o.estimators import (H2OGradientBoostingEstimator,\r\n",
    "                            H2ORandomForestEstimator)\r\n",
    "from IPython.display import display\r\n",
    "from scipy.stats import spearmanr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.options.display.max_rows = 999 \r\n",
    "pd.options.display.max_columns = 999\r\n",
    "sns.set_palette(\"colorblind\")\r\n",
    "\r\n",
    "print(IPython.sys_info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 2. DATA UNDERSTANDING. CLEAN, TRANSFORM, PREPROCESS DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Collect Initial Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read beer file\r\n",
    "beer_all = pd.read_excel(\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_input/beer_241.xlsx\", sheet_name=\"Sheet1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Describe Data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write function that takes any dataframe and displays basic details about it.\r\n",
    "# Use display() because it automatically adds an empty line between outputs, instead of print() which doesn't.\r\n",
    "\r\n",
    "def inspect_function(df):\r\n",
    "    \"\"\"Display dataframe properties.\"\"\"\r\n",
    "    \r\n",
    "    display(df.shape)\r\n",
    "    display(df.head())\r\n",
    "    display(df.info())\r\n",
    "    display(df.isna().sum())\r\n",
    "    display(df.describe().round(1))\r\n",
    "    \r\n",
    "inspect_function(beer_all)\r\n",
    "# Rating is between -1 and 11."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Standardize appeareance. Convert column labels to lowercase.\r\n",
    "beer_all.columns = beer_all.columns.str.lower()\r\n",
    "\r\n",
    "# Convert columns values to lowercase if they are strings.\r\n",
    "beer_all = beer_all.applymap(lambda col:col.lower() if type(col) == str else col)\r\n",
    "\r\n",
    "# Convert Name column from object to string.\r\n",
    "beer_all[\"name\"] = beer_all[\"name\"].astype(\"string\")\r\n",
    "\r\n",
    "# Cut alcohol content from end of name and store as separate column.\r\n",
    "beer_all[\"abv\"] = [name.rsplit(maxsplit=1)[-1] for name in beer_all[\"name\"]]\r\n",
    "\r\n",
    "# Convert alcohol content to float.\r\n",
    "beer_all[\"abv\"] = beer_all[\"abv\"].astype(float)\r\n",
    "\r\n",
    "# Convert object types to category, except Split column.\r\n",
    "beer_all[[\"method\", \"style\", \"flavor\", \"fermentation\"]] = beer_all[[\"method\", \"style\", \"flavor\", \"fermentation\"]].astype(\"category\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Validation of uniqueness in beer names. Check for duplicates, remove if found.\r\n",
    "beer_all.drop_duplicates(subset=\"name\", keep=\"last\", inplace=True)\r\n",
    "\r\n",
    "# Description of numeric variables after standardized appearance and after removal of duplicates.\r\n",
    "inspect_function(beer_all)\r\n",
    "# At the beginning there were 241 rows and 8 columns, now there are 240 rows and 9 columns.\r\n",
    "\r\n",
    "# Percentage of beer with ratings lower than 5.\r\n",
    "under_5_rating = beer_all[\"rating\"] < 5\r\n",
    "under_5_rating_percentage = (len(beer_all[under_5_rating])/len(beer_all[\"rating\"]))*100\r\n",
    "print(f\"Currently {under_5_rating_percentage:.1f}% of total beers are discarded.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Description of categorical variables.\r\n",
    "\r\n",
    "def describe_categorical_columns(df, numeric_column):\r\n",
    "    \"\"\"Print basic statistics of subgroups in categorical columns.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing numerical and categorical columns.\r\n",
    "    numeric_column (str): Name of the column containing numerical data.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Print basic statistics of each column containing categorical data: count, mean, std, min, 25%, 50%, 75%, max.\r\n",
    "    \"\"\"\r\n",
    "    # Store in a list the columns containing categorical data:\r\n",
    "    list_categoricals = df.select_dtypes(include=[\"category\"]).columns.tolist()\r\n",
    "    # Iterate through list of categorical columns:\r\n",
    "    for i, elem in enumerate(list_categoricals):\r\n",
    "        description = df.groupby([elem])[numeric_column].describe().round(1)\r\n",
    "        print(description)\r\n",
    "\r\n",
    "describe_categorical_columns(beer_all, \"rating\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Descrition of Country column.\r\n",
    "country_unique = len(set(beer_all[\"country\"])) \r\n",
    "print(f\"There are {country_unique} unique countries.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Explore Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "### Hypothesis 1: There might be a linear relationship between ratings and alcohol content."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot alcohol content vs. rating by subgroup to check for hidden patterns.\r\n",
    "\r\n",
    "def scatter_sns(df, x_numeric_column, y_numeric_column):\r\n",
    "    \"\"\"Seaborn scatter type subplots of two numeric variables as x and y, grouped by categorical columns.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing numerical and categorical columns.\r\n",
    "    x_numeric_column (str): Name of numerical column to be plotted on x-axis.\r\n",
    "    y_numeric_column (str): Name of numerical column to be plotted on y-axis.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Seaborn scatter type subplots of x and y series, split by subgroups of categorical columns used as hue.\r\n",
    "    Title and name of axes are added automatically based on the name of x and y series.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Store in a list the columns containing categorical data:\r\n",
    "    list_categoricals = df.select_dtypes(include=[\"category\"]).columns.tolist()\r\n",
    "\r\n",
    "    # Calculate the number of subplots in the figure:\r\n",
    "    number_of_plots = len(list_categoricals)\r\n",
    "    # Set the number of columns to 3 because it fits most screens:\r\n",
    "    number_of_cols = 3\r\n",
    "    # Calculate the number of rows in which subplots are shown:\r\n",
    "    number_of_rows = ceil(number_of_plots/number_of_cols)\r\n",
    "\r\n",
    "    # Plot figure and set title:\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.suptitle(f\"relationship between {df[x_numeric_column].name} and {df[y_numeric_column].name} by each categorical feature\".title())\r\n",
    "    \r\n",
    "    # Iterate through list of categorical columns:\r\n",
    "    for i, elem in enumerate(list_categoricals):\r\n",
    "        # Add subplots sequentially.\r\n",
    "        # Mark the first subplot as i+1 because subplot indices start at 1, and list indeces start at 0.\r\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_cols, i+1)\r\n",
    "        # Create each subplot, set title of subplot, labels and legend:\r\n",
    "        sns.scatterplot(x=df[x_numeric_column], y=df[y_numeric_column], hue=elem, data=df, s=15)\r\n",
    "        ax.set_title(elem.title(), fontsize=12, verticalalignment=\"bottom\", y=0.95)\r\n",
    "        ax.set(xlabel=df[x_numeric_column].name.capitalize(), ylabel=df[y_numeric_column].name.capitalize())\r\n",
    "        ax.legend(fontsize=5, loc=\"best\")\r\n",
    "        # In VS Code the legend is upper left in minimized window and in best location when maximized.      \r\n",
    "    plt.show()\r\n",
    "\r\n",
    "scatter_sns(beer_all, \"abv\", \"rating\")\r\n",
    "\r\n",
    "# Result 1: The scatterplot shows no linear relationship and no pattern between ratings and ABV.\r\n",
    "# However, subgroup of lemon flavor with zero or low ABV has higher ratings compared to other groups."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothesis 2: Some subgroups might have a low number of observations and lead to overfitting the machine learning model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create column to store status of occurrences.\r\n",
    "beer_all[\"occurrence\"] = np.nan\r\n",
    "\r\n",
    "# Count occurrences in subgroups of categorical data and return df with subgroups below threshold.\r\n",
    "def select_too_few_categorical_observations(df, categorical_columns, occurrence_column, threshold_percentage):\r\n",
    "    \"\"\"Count observations of categorical features and store result in custom column.\r\n",
    "\r\n",
    "    If subgroup has less observations than threshold, mark them as too_few in a results column.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing categorical columns.\r\n",
    "    categorical_columns (list): List of categorical columns.\r\n",
    "    occurrence_column (int): Name of column that stores the count of occurrences.\r\n",
    "    threshold_percentage (int, float): Percentage of minimum observations from total.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    df (pandas.DataFrame): Selection from original dataframe.\r\n",
    "    Rows contain subgroups with counted observations less than threshold.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Calculate the number of rows needed to pass the threshold, and print result.\r\n",
    "    threshold = len(df)*threshold_percentage/100\r\n",
    "    print(f\"The threshold is {threshold} observations or more.\")\r\n",
    "\r\n",
    "    # Iterate through list of categorical columns and count occurrences of subgroups:\r\n",
    "    for i, elem in enumerate(categorical_columns):\r\n",
    "        counted = df[elem].value_counts()\r\n",
    "    # Convert counts to dictionary:\r\n",
    "        counted_dictionary = counted.to_dict()\r\n",
    "    # Iterate through dictionary and store result if too_few:\r\n",
    "        for key, value in counted_dictionary.items():\r\n",
    "            if value < threshold:\r\n",
    "                df.loc[df[elem] == key, occurrence_column] = \"too_few\"\r\n",
    "                print(f\"Too few {key} {elem}.\")\r\n",
    "    # Fill occurrence column with \"enough\" if the record was not marked as too_few:\r\n",
    "    for elem in df[occurrence_column]:\r\n",
    "        if elem != \"too_few\":\r\n",
    "            df.loc[df[occurrence_column] != \"too_few\", occurrence_column] = \"enough\"\r\n",
    "    # Select rows with too_few observations:\r\n",
    "    too_few = df.loc[df[occurrence_column] == \"too_few\"]\r\n",
    "    return too_few\r\n",
    "\r\n",
    "# Define list of categorical features to be checked and set a threshold of 5% from the total.\r\n",
    "categoricals = [\"method\", \"style\", \"flavor\", \"fermentation\"]\r\n",
    "too_few_subgroups = select_too_few_categorical_observations(beer_all, categoricals, \"occurrence\", 5)\r\n",
    "\r\n",
    "# Result 2: Style and Flavor columns have subgroups below the 5% threshold of the total observations."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothesis 3: Flavor column might have observable variation between its subgroups."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = sns.barplot(x=\"flavor\", y=\"rating\", data=beer_all)\r\n",
    "g.axhline(y=beer_all[\"rating\"].mean(), linestyle=\"dotted\", color=\"black\")\r\n",
    "g.set(xlabel=\"Flavor\", ylabel=\"Rating\", title=\"Average Rating Of Style Subgroups\")\r\n",
    "g.set_ylim([0, 10])\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Result 3: Flavor subgroups have observable variation between their average.\r\n",
    "# The errorbar is bigger on herb subgroup."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothesis 4: Lemon beers’ high average might not be due to outliers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = sns.boxplot(x=\"flavor\", y=\"rating\", data=beer_all)\r\n",
    "g.axhline(y=beer_all[\"rating\"].median(), linestyle=\"dotted\", color=\"black\")\r\n",
    "g.set(xlabel=\"Flavor\", ylabel=\"Rating\", title=\"Distribution Of Ratings In Flavor Subgroups\")\r\n",
    "g.set_ylim([0, 10])\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Result 4: The boxplot shows that the distribution of lemon beers is due to higher ratings overall compared to other subgroups.\r\n",
    "# There's no median on the lemon box. Let's find out why."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's investigate what's going on with the lineless box of lemon ratings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if lemon median equals one of the quantiles, remember median is 0.50 quantile.\r\n",
    "lemon_ratings = beer_all[beer_all[\"flavor\"] == \"lemon\"][\"rating\"]\r\n",
    "print(lemon_ratings.quantile([0.25, 0.50, 0.75]))\r\n",
    "# That's it, 0.50 and 0.75 quantile are equal, so that's why the unusual boxplot.\r\n",
    "# Both 50% and 75% of all lemon ratings are higher or equal to 8.\r\n",
    "\r\n",
    "# Check distribution of lemon beer ratings to see if the quantile explanation matches the graph.\r\n",
    "g = sns.kdeplot(x=lemon_ratings)\r\n",
    "g.set(title=\"KDE of Lemon Beer Rating\", xlabel=\"Rating\")\r\n",
    "g.set_xticks(range(-1, 12))\r\n",
    "plt.show()\r\n",
    "# There's a peak of observations where the rating is 8.\r\n",
    "# More than half of the distribution is on the left side of the 8 mark, so 75% looks plausible.\r\n",
    "\r\n",
    "# Conclusion: The ratings of lemon beers are so much higher than the rest, that their median overlaps with its 75th percentile."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Verify Data Quality"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data coverage in numerical variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data coverage in ratings.\r\n",
    "unique_ratings = np.unique(beer_all[\"rating\"])\r\n",
    "unique_ratings_list = list(unique_ratings)\r\n",
    "print(f\"Uniques values of ratings are {unique_ratings_list}\")\r\n",
    "\r\n",
    "# Data coverage in abv.\r\n",
    "unique_abv = np.unique(beer_all[\"abv\"])\r\n",
    "unique_abv_list = list(unique_abv)\r\n",
    "print(f\"Uniques values of alcohol content are {unique_abv_list}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data coverage in categorical variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def countplot_sns(df):\r\n",
    "    \"\"\"Count of observations in each subgroup of categorical columns, plotted as bars.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing categorical columns.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Seaborn countplot in subplots for co unting observations in each subgroup ofcategorical columns.\r\n",
    "    Bars in descending order of counts.\r\n",
    "    Axes labels are added automatically based on column names.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Select columns with data type category:\r\n",
    "    list_categoricals = df.select_dtypes(include=[\"category\"]).columns.tolist()\r\n",
    "    # Calculate the number of subplots in the figure:\r\n",
    "    number_of_plots = len(list_categoricals)\r\n",
    "    # Set the number of columns to 3 because it fits most screens:\r\n",
    "    number_of_cols = 3\r\n",
    "    # Calculate the number of rows in which subplots are shown:\r\n",
    "    number_of_rows = ceil(number_of_plots/number_of_cols)\r\n",
    "\r\n",
    "    # Plot figure and set title:\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.suptitle(\"count of observations in each subgroup of categorical columns\".title())\r\n",
    "    # Iterate through list of categorical columns:\r\n",
    "    for i, elem in enumerate(list_categoricals):\r\n",
    "        # Define bar sorting criteria as descending counts:\r\n",
    "        desc_order = df[elem].value_counts().index\r\n",
    "        # Add subplots sequentially.\r\n",
    "        # Mark the first subplot as i+1 because subplot indices start at 1, and list indeces start at 0.\r\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_cols, i+1)\r\n",
    "        # Create each subplot, set labels and legend:\r\n",
    "        sns.countplot(x=elem, data=df, order=desc_order)\r\n",
    "        ax.set_title(elem.title(), fontsize=12, verticalalignment=\"bottom\", y=0.95)\r\n",
    "        ax.set_xticklabels(desc_order, fontsize=6, rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "        ax.set(xlabel=\"\", ylabel=\"\")\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "countplot_sns(beer_all)\r\n",
    "# Size of subgroups consistent with stores' assortment."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 3. DATA PREPARATION"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Select Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1 Distribution of ratings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = sns.kdeplot(x=beer_all[\"rating\"])\r\n",
    "g.set(title=\"KDE Of Rating\", xlabel=\"Rating\")\r\n",
    "g.set_xticks(range(-1, 12))\r\n",
    "plt.show()\r\n",
    "# Curve of ratings KDE is gaussian."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 Distribution of alcohol content."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Commercial beer is either regular, alcohol-free, or lemonade mix, and a smooth curve hides these groups.\r\n",
    "# Set bandwidth lower than 1 to check if groups show up.  \r\n",
    "g = sns.kdeplot(x=beer_all[\"abv\"], label=\"smoothed curve\")\r\n",
    "g = sns.kdeplot(x=beer_all[\"abv\"], bw_adjust=0.3, label=\"focused curve\")\r\n",
    "g.set(title=\"KDE Of Alcohol Content\", xlabel=\"Alcohol content\")\r\n",
    "g.set_xticks(range(0, 11))\r\n",
    "g.legend()\r\n",
    "plt.show()\r\n",
    "# Curve of alcohol content KDE is not gaussian.\r\n",
    "# Still, it shows a pattern of three subgroups each with its own gaussian curve.\r\n",
    "\r\n",
    "# Check proportion of alcohol-free beer because it influences the curve of alcohol content.\r\n",
    "abv_list = beer_all[\"abv\"].tolist()\r\n",
    "abv_zero = (abv_list.count(0)/len(abv_list))*100\r\n",
    "print(f\"Alcohol-free are {abv_zero:.2f}% of total beer.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.3 Combined distribution of alcohol content and ratings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate Spearman's correlation coefficient because it works for non-linear relationship if the variables are monotonic.\r\n",
    "spearman_corr, _ = spearmanr(beer_all[\"abv\"], beer_all[\"rating\"])\r\n",
    "print(f\"Spearman\\'s correlation: {spearman_corr:.2f}.\")\r\n",
    "# Result: -0.11, so if they have any kind of relationship, it is not monotonic.\r\n",
    "# The scatterplot between abv and rating is consistent with Spearman's correlation coefficient.\r\n",
    "\r\n",
    "# Plot KDE of alcohol content and rating. Set bandwidth less than 1 because distribution of ABV is not gaussian.\r\n",
    "g = sns.kdeplot(data=beer_all, x=beer_all[\"abv\"], y=beer_all[\"rating\"], bw_adjust=0.7)\r\n",
    "g.set(title=\"KDE of alcohol content and rating\", xlabel=\"Alcohol content\", ylabel=\"Rating\")\r\n",
    "plt.show() \r\n",
    "# There are three zones, so it makes sense to split the dataset into three groups after all cleanup is done."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.4 Check country column if it has enough observations for each unique value, otherwise drop the column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Count occurrences for each country.\r\n",
    "country_count = beer_all[\"country\"].value_counts()\r\n",
    "\r\n",
    "# Count occurrences for each country as percentage.\r\n",
    "country_percentage = beer_all[\"country\"].value_counts(normalize=True).mul(100).round(1)\r\n",
    "\r\n",
    "# Collect all results in one dataframe.\r\n",
    "country_stats = pd.DataFrame({\"observations\": country_count, \"percentage\": country_percentage})\r\n",
    "# print(country_stats)\r\n",
    "# There are 17 unique countries and 15 of them have each less than 5% of the total observations.\r\n",
    "\r\n",
    "# Drop country column.\r\n",
    "beer_all = beer_all.drop(\"country\", 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.5 Check which categorical features have high variation across subgroups for building models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot ratings variation in subgroups across categorical features.\r\n",
    "\r\n",
    "def barplot_sns(df, y_numeric_column, graph_title, categorical_columns=None):\r\n",
    "    \"\"\"Seaborn subplots of bars showing mean of numeric column grouped by categorical columns.\r\n",
    "    If list of categorical columns is not provided, uses columns of category type from dataframe.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing numerical and categorical columns.\r\n",
    "    y_series (str): Name of numerical column.\r\n",
    "    graph_title (str): Title of graph.\r\n",
    "    categorical_columns (list, optional): List of categorical columns.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Seaborn subplots of bars with mean of each subgroup in categorical columns.\r\n",
    "    Horizontal line to mark the mean of each column. Bars in descending order of mean.\r\n",
    "    Axes labels are added automatically based on column names.\r\n",
    "    \"\"\"\r\n",
    "    # Check if input contains list of categorical columns. If not, select columns with data type category:\r\n",
    "    if categorical_columns != None:\r\n",
    "        list_categoricals = categorical_columns\r\n",
    "    else:\r\n",
    "        list_categoricals = df.select_dtypes(include=[\"category\"]).columns.tolist()\r\n",
    "    \r\n",
    "    # Calculate the number of subplots in the figure:\r\n",
    "    number_of_plots = len(list_categoricals)\r\n",
    "    # Set the number of columns to 3 because it fits most screens:\r\n",
    "    number_of_cols = 3\r\n",
    "    # Calculate the number of rows in which subplots are shown:\r\n",
    "    number_of_rows = ceil(number_of_plots/number_of_cols)\r\n",
    "\r\n",
    "    # Plot figure and set title:\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.suptitle(graph_title.title())\r\n",
    "    # Iterate through list of categorical columns:\r\n",
    "    for i, elem in enumerate(list_categoricals):\r\n",
    "    # Define bar sorting criteria as descending mean:\r\n",
    "        desc_order = list(df.groupby(elem)[y_numeric_column].mean().reset_index().sort_values(by=y_numeric_column, ascending=False)[elem])\r\n",
    "        # Add subplots sequentially.\r\n",
    "        # Mark the first subplot as i+1 because subplot indices start at 1, and list indeces start at 0.\r\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_cols, i+1)\r\n",
    "        # Create each subplot, set horizontal line to mark the mean, set labels and legend:\r\n",
    "        sns.barplot(x=elem, y=y_numeric_column, data=df, order=desc_order, dodge=False)\r\n",
    "        ax.axhline(y=df[y_numeric_column].mean(), linestyle=\"dotted\", color=\"black\")\r\n",
    "        ax.set_title(elem.title(), fontsize=12, verticalalignment=\"bottom\", y=0.95)\r\n",
    "        ax.set_xticklabels(desc_order, fontsize=6, rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "        ax.set(xlabel=\"\", ylabel=\"\")\r\n",
    "        ax.set_ylim([0, 10])\r\n",
    "        \r\n",
    "    plt.show()\r\n",
    " \r\n",
    "barplot_sns(beer_all, \"rating\", \"average rating of beer subgroups\", categoricals)\r\n",
    "\r\n",
    "\r\n",
    "# The barplot shows Flavor and Style have high variation between the average of their subgroups.\r\n",
    "# Method and Fermentation have low variation across their subgroups.\r\n",
    "# Errorbars are bigger on subgroups with low number of observations."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explain sequence for sorting bars of categoricals by value counts (numerical values) in the previous function. Use subgroups of flavor column as example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Start grouping all rows by flavor and select only the rating column, then calculate its mean.\r\n",
    "# Reset the index to avoid future errors.\r\n",
    "grouped = beer_all.groupby(\"flavor\")[\"rating\"].mean().reset_index()\r\n",
    "# Then sort this series by ratings in descending order and select flavor labels.\r\n",
    "ordered = grouped.sort_values(by=\"rating\", ascending=False)[\"flavor\"]\r\n",
    "# Lastly, turn these grouped and ordered flavor labels into a list ready to use when creating graphs.\r\n",
    "stored_in_list = list(ordered)\r\n",
    "# In a more concise (and hard to read) line, the flow looks like this:\r\n",
    "desc_order = list(beer_all.groupby(\"flavor\")[\"rating\"].mean().reset_index().sort_values(by=\"rating\", ascending=False)[\"flavor\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Abstract representation of ratings distribution. Take a look at median, IQR, whiskers, outliers.\r\n",
    "\r\n",
    "def boxplot_sns(df, y_numeric_column, graph_title, categorical_columns=None):\r\n",
    "    \"\"\"Seaborn subplots with boxplots of subgroups' distribution in categorical columns.\r\n",
    "    If list of categorical columns is not provided, uses columns of category type from dataframe.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    df (pandas.DataFrame): Dataframe containing numerical and categorical columns.\r\n",
    "    y_series (str): Name of numerical column.\r\n",
    "    graph_title (str): Title for graph.\r\n",
    "    categorical_columns (list, optional): List of categorical columns.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Seaborn subplots of boxplots showing distribution of subgroups in categorical columns.\r\n",
    "    Boxes in descending order of median.\r\n",
    "    Axes labels are added automatically based on column names.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Check if input contains list of categorical columns. If not, select columns with data type category:\r\n",
    "    if categorical_columns != None:\r\n",
    "        list_categoricals = categorical_columns\r\n",
    "    else:\r\n",
    "        list_categoricals = df.select_dtypes(include=[\"category\"]).columns.tolist()\r\n",
    "    \r\n",
    "    # Calculate the number of subplots in the figure:\r\n",
    "    number_of_plots = len(list_categoricals)\r\n",
    "    # Set the number of columns to 3 because it fits most screens:\r\n",
    "    number_of_cols = 3\r\n",
    "    # Calculate the number of rows in which subplots are shown:\r\n",
    "    number_of_rows = ceil(number_of_plots/number_of_cols)\r\n",
    "    \r\n",
    "    # Plot figure and set title:\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.suptitle(graph_title.title())\r\n",
    "    # Iterate through list of categorical columns:\r\n",
    "    for i, elem in enumerate(list_categoricals):\r\n",
    "        # Define box sorting criteria as descending median:\r\n",
    "        desc_order = list(df.groupby(elem)[y_numeric_column].median().reset_index().sort_values(by=y_numeric_column, ascending=False)[elem])\r\n",
    "        # Add subplots sequentially.\r\n",
    "        # Mark the first subplot as i+1 because subplot indices start at 1, and list indeces start at 0.\r\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_cols, i+1)\r\n",
    "        # Create each subplot, set labels and legend:\r\n",
    "        sns.boxplot(x=elem, y=y_numeric_column, data=df, order=desc_order)\r\n",
    "        ax.set_title(elem.title(), fontsize=12, verticalalignment=\"bottom\", y=0.95)\r\n",
    "        ax.set_xticklabels(desc_order, fontsize=6, rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "        ax.set(xlabel=\"\", ylabel=\"\")\r\n",
    "        ax.set_ylim([0, 10])\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "boxplot_sns(beer_all, \"rating\", \"Rating distribution of beer subgroups\", categoricals)\r\n",
    "\r\n",
    "# The boxplot shows Flavor and Style have high variation between the distributions of their subgroups.\r\n",
    "# Method and Fermentation have low variation across their subgroups.\r\n",
    "# Errorbars are bigger on subgroups with low number of observations."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Clean data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define range of normal ratings as 2*std away from the mean because dataset is small and has gaussian distribution.\r\n",
    "mean_rating = beer_all[\"rating\"].mean()\r\n",
    "std_rating = beer_all[\"rating\"].std()\r\n",
    "two_std_rating = std_rating * 2\r\n",
    "\r\n",
    "lower_limit_rating = mean_rating - two_std_rating\r\n",
    "upper_limit_rating = mean_rating + two_std_rating\r\n",
    "\r\n",
    "print(f\"The mean rating is {mean_rating:.2f}.\")\r\n",
    "print(f\"The lower limit of normal ratings is {lower_limit_rating:.2f} and the upper limit is {upper_limit_rating:.2f}.\")\r\n",
    "\r\n",
    "# Identify rating outliers. Use result to train machine learning model and avoid overfitting.\r\n",
    "outlier_ratings = [x for x in beer_all[\"rating\"] if x < lower_limit_rating or x > upper_limit_rating]\r\n",
    "outlier_ratings.sort()\r\n",
    "# print(f\"These are the rating outliers: {outlier_ratings}\")\r\n",
    "print(f\"There are {len(outlier_ratings)} outliers out of {len(beer_all.rating)} total rating observations.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Construct Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1 Derived Attributes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create column for filtration status.\r\n",
    "unfiltered_words = [\"unfiltered\", \"kellerbier\", \"natur\", \"naturtrubes\", \"nefiltrata\", \"nonfiltrata\"]\r\n",
    "beer_all[\"filtration\"] = beer_all[\"name\"].str.contains(\"|\".join(unfiltered_words))\r\n",
    "beer_all[\"filtration\"] = beer_all[\"filtration\"].replace({True: \"unfiltered\", False: \"filtered\"})\r\n",
    "\r\n",
    "# Create column for pasteurization status.\r\n",
    "unpasteurized_words = [\"unpasteurized\", \"kellerbier\", \"natur\", \"naturtrubes\", \"nepasteurizata\", \"nonpastorizzata\"]\r\n",
    "beer_all[\"pasteurization\"] = beer_all[\"name\"].str.contains(\"|\".join(unpasteurized_words))\r\n",
    "beer_all[\"pasteurization\"] = beer_all[\"pasteurization\"].replace({True: \"unpasteurized\", False: \"pasteurized\"})\r\n",
    "\r\n",
    "# Format the new columns as categoricals.\r\n",
    "beer_all[[\"filtration\", \"pasteurization\"]] = beer_all[[\"filtration\", \"pasteurization\"]].astype(\"category\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.2 Generated records."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create column to bin alcohol content as categorical data.\r\n",
    "abv_bins = [0, 0.5, 2.8, 4.4, 5.5, max(beer_all[\"abv\"])]\r\n",
    "perception_labels = [\"drive\", \"refresh\", \"weak\", \"tasty\", \"too_strong\"]\r\n",
    "beer_all[\"perception\"] = pd.cut(beer_all[\"abv\"], bins=abv_bins, labels=perception_labels, include_lowest=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 Integrate Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3.4.1 Select observations with ratings less than 2*std away from the mean. Use limits calculated at 3.2 and reset index.\r\n",
    "outlier_condition = (beer_all.rating < lower_limit_rating) | (beer_all.rating > upper_limit_rating)\r\n",
    "beer_2std = beer_all.drop(beer_all[outlier_condition].index)\r\n",
    "beer_2std.reset_index(inplace=True, drop=True)\r\n",
    "print(f\"Dataframe without outliers has {len(beer_2std.rating)} rows.\")\r\n",
    "# Check this out, below selection by square brackets doesn't work in f-string, must use dot notation.\r\n",
    "# print(f\"There are {len(beer_2std[\"rating\"])} observations with normal ratings.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3.4.2 Split dataset by alcohol content into three subsets: alcohol-free, light and regular beer.\r\n",
    "alc_free_all = beer_all[beer_all[\"abv\"] <= 0.5]\r\n",
    "light_all = beer_all[(beer_all[\"abv\"] > 0.5) & (beer_all[\"abv\"] <= 3)]\r\n",
    "regular_all = beer_all[beer_all[\"abv\"] > 3]\r\n",
    "\r\n",
    "alc_free_2std = beer_2std[beer_2std[\"abv\"] <= 0.5]\r\n",
    "light_2std = beer_2std[(beer_2std[\"abv\"] > 0.5) & (beer_2std[\"abv\"] <= 3)]\r\n",
    "regular_2std = beer_2std[beer_2std[\"abv\"] > 3]\r\n",
    "\r\n",
    "print(f\"In complete ratings range there are {len(alc_free_all)} alcohol-free, {len(light_all)} light and {len(regular_all)} regular beers.\")\r\n",
    "print(f\"In less than 2*std away ratings there are {len(alc_free_2std)} alcohol-free, {len(light_2std)} light and {len(regular_2std)} regular beers.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3.4.3 Check distribution of ratings in subsets\r\n",
    "# Plot distribution of ratings in each subset to check if their curves are gaussian.\r\n",
    "g = sns.kdeplot(x=alc_free_all[\"rating\"], label=\"all\")\r\n",
    "g = sns.kdeplot(x=alc_free_2std[\"rating\"], label=\"2_std\")\r\n",
    "g.set(title=\"Alcohol-free Beer Ratings\", xlabel=\"Rating\")\r\n",
    "g.set_xticks(range(-1, 12))\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "g = sns.kdeplot(x=light_all[\"rating\"], label=\"all\")\r\n",
    "g = sns.kdeplot(x=light_2std[\"rating\"], label=\"2_std\")\r\n",
    "g.set(title=\"Light Beer Ratings\", xlabel=\"Rating\")\r\n",
    "g.set_xticks(range(-1, 12))\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "g = sns.kdeplot(x=regular_all[\"rating\"], label=\"all\")\r\n",
    "g = sns.kdeplot(x=regular_2std[\"rating\"], label=\"2_std\")\r\n",
    "g.set(title=\"Regular Beer Ratings\", xlabel=\"Rating\")\r\n",
    "g.set_xticks(range(-1, 12))\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "# KDE plots of the six subsets prove that ratings keep their gaussian curve even if split by alcohol content criteria."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dictionary that stores datasets as values and their names as keys.\r\n",
    "clean_dataframes = [beer_all, alc_free_all, light_all, regular_all, beer_2std, alc_free_2std, light_2std, regular_2std]\r\n",
    "dataframe_names = [\"beer_all\", \"alc_free_all\", \"light_all\", \"regular_all\", \"beer_2std\", \"alc_free_2std\", \"light_2std\", \"regular_2std\"]\r\n",
    "\r\n",
    "dataframes_dict = dict(zip(dataframe_names, clean_dataframes))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3.4.4 Check feature variation across subgroups when split into the three subsets based on alcohol content.\r\n",
    "\r\n",
    "for key, value in dataframes_dict.items():\r\n",
    "    boxplot_sns(value, \"rating\", f\"Distribution of {key}\")\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "# All subsets have higher variation in Style and Flavor, and no variation in Method.\r\n",
    "# Some subsets have a bit of variation in Filtration, Pasteurization, Fermentation and Perception."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5 Format Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Sort df on ABV, then on rating.\r\n",
    "beer_all.sort_values([\"rating\", \"abv\"], ascending=[True, True], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.6 Dataset - output."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Export dataframes and remove index because beer identification is done through their unique name.\r\n",
    "# It's also good to avoid having two columns with indices next time the file is imported.\r\n",
    "\r\n",
    "def export_files_csv(dataframes_dictionary, output_folder):\r\n",
    "    \"\"\"Export dictionary of pandas DataFrames to csv files\r\n",
    "    Must have names as keys and dataframes as values.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    dataframes_dictionary (dict): Dictionary of dataframes to be exported.\r\n",
    "    output_folder (str): Path to folder where to export result.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    csv files.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    for key, value in dataframes_dictionary.items():\r\n",
    "        output_address = output_folder + str(key) + \".csv\"\r\n",
    "        value.to_csv(output_address, index=False)\r\n",
    "\r\n",
    "# Path to folder containing clean files.\r\n",
    "clean_files_path = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_output/cleaning_output/\"\r\n",
    "\r\n",
    "\r\n",
    "export_files_csv(dataframes_dict, clean_files_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.7 Dataset Description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print total number of columns, rows and ratings lower than 5.\r\n",
    "# Print description of categorical columns.\r\n",
    "\r\n",
    "for key, value in dataframes_dict.items():\r\n",
    "    total_rows = value.shape[0]\r\n",
    "    lower_than_five = value[value[\"rating\"] < 5]\r\n",
    "    only_lows = lower_than_five.shape[0]\r\n",
    "    total_columns = value.shape[1]\r\n",
    "    print(f\"{key} \\nRows: {total_rows} \\nNumber of ratings lower than 5: {only_lows} \\nColumns: {total_columns} \\n\")\r\n",
    "    describe_categorical_columns(value, \"rating\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 4. MODELING. MACHINE LEARNING WITH H2O"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize H2O"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assertions are disabled because they are mainly used for error checking and debugging purposes.\r\n",
    "# nthreads=-1 means use all CPU on the host\r\n",
    "h2o.init(nthreads=-1, enable_assertions=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect .csv files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select clean files.\r\n",
    "clean_files = glob.glob(clean_files_path + \"*.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import datasets as dictionaries into H2O."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write function to import multiple files at once.\r\n",
    "\r\n",
    "def files_to_h2o_frames(files, response_column):\r\n",
    "    \"\"\"Import files into H2O frames.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "    files (list): List of files to be imported.\r\n",
    "    response_column (str): Name of response column.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    dict: Dictionary containing H2O frames, predictors and response.\r\n",
    "    Key: the name of a dataset. Values: the imported frame, its list of predictors, the response column.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Create empty dictionary to be populated at each iteration.\r\n",
    "    dictionary = {}\r\n",
    "\r\n",
    "    # Iterate through list of files to create name, frame and list of predictors.\r\n",
    "    for i, elem in enumerate(files):\r\n",
    "        name = PureWindowsPath(elem).stem\r\n",
    "        frame = h2o.import_file(elem)\r\n",
    "        if \"beer\" in name:\r\n",
    "            predictors = [\"style\", \"flavor\", \"perception\", \"abv\"]\r\n",
    "        elif \"alc_free\" in name:\r\n",
    "            predictors = [\"style\", \"flavor\"]\r\n",
    "        elif \"light\" in name:\r\n",
    "            predictors = [\"style\", \"flavor\", \"abv\"]\r\n",
    "        else:\r\n",
    "            predictors = [\"style\", \"flavor\", \"pasteurization\", \"abv\"]\r\n",
    "\r\n",
    "        # Add key and values to dictionary.\r\n",
    "        dictionary[name] = {\"frame\":frame, \"predictors\":predictors, \"response\": response_column}\r\n",
    "    return dictionary\r\n",
    "\r\n",
    "frames_dictionary = files_to_h2o_frames(clean_files, \"rating\")\r\n",
    "\r\n",
    "# Print the resulting dictionaries to check if they look right.\r\n",
    "print(frames_dictionary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Select Modeling Techniques."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DRF, GBM - see motives in Readme file."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Generate Test Design."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The model will learn from the training set and will be assessed on the test set.\r\n",
    "# Train 0.7, valid 0.15 and test 0.15 splits were decided manually to ensure they are diverse no matter how few observations there are.\r\n",
    "# See note in Readme file."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Build Models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3.1 Distributed Random Forest - DRF."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write function to generate DRF model and export prediction as pandas dataframe.\r\n",
    "\r\n",
    "def model_h2o_drf(frames, pred_output_folder, mse_output_folder):\r\n",
    "    \"\"\"Build DRF model in H2O for each dataset, add prediction to pandas dataframe, export result and MSE as csv.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    frames (dict): Dictionary containing frames, predictors and response column.\r\n",
    "    pred_output_folder (str): Path to folder where to export DRF model.\r\n",
    "    mse_output_folder (str): Path to folder where to export file with MSE of all DRF models.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    zip archive of each model\r\n",
    "    csv file with predictions of each model\r\n",
    "    csv file with MSE of all DRF models\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Create list of model names.\r\n",
    "    model_names = []\r\n",
    "\r\n",
    "    # Create list of MSE results from each model.\r\n",
    "    mse_list = []\r\n",
    "\r\n",
    "    # Iterate through dictionary and store its elements under short variable names to help with readability:\r\n",
    "    for key, value in frames.items():\r\n",
    "        # Access the name.\r\n",
    "        name = str(key)+ \"_drf\"\r\n",
    "\r\n",
    "        # Append model name to list.\r\n",
    "        model_names.append(name)\r\n",
    "\r\n",
    "        # Access the frame.\r\n",
    "        frame = frames[key][\"frame\"]\r\n",
    "        # Access the predictors.\r\n",
    "        predictor_list = frames[key][\"predictors\"]\r\n",
    "        # Access the response.\r\n",
    "        response_column = frames[key][\"response\"]\r\n",
    "\r\n",
    "        # Split rows into training, validation and test sets. This makes reproducibility possible.\r\n",
    "        train = frame[frame[\"split\"]==\"train\"]\r\n",
    "        valid = frame[frame[\"split\"]==\"valid\"]\r\n",
    "        test = frame[frame[\"split\"]==\"test\"]\r\n",
    "\r\n",
    "        # Instantiate model with custom parameters.   \r\n",
    "        model = H2ORandomForestEstimator(seed=12, categorical_encoding=\"Enum\", nfolds=4, fold_assignment=\"random\", \r\n",
    "        mtries=len(predictor_list), nbins=13, nbins_top_level=16, build_tree_one_node=True)\r\n",
    "\r\n",
    "        # Train model. Specify predictors, response column, training frame and validation frame.\r\n",
    "        model.train(x=predictor_list, y=response_column, training_frame=train, validation_frame=valid, model_id=name+\"_model\")\r\n",
    "\r\n",
    "        # Print model to show variable importance.\r\n",
    "        # print(model)\r\n",
    "\r\n",
    "        # Export model.\r\n",
    "        model_file = model.download_mojo(path=\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/models/drf_models\", get_genmodel_jar=False)\r\n",
    "\r\n",
    "        # Generate prediction. It gets stored in a H2O frame with one column named \"predict\".\r\n",
    "        prediction = model.predict(frame)\r\n",
    "\r\n",
    "        # Calculate model performance on test set.\r\n",
    "        performance = model.model_performance(test)\r\n",
    "\r\n",
    "        # Store model performance as json into a dictionary.\r\n",
    "        perf_dict = performance._metric_json\r\n",
    "\r\n",
    "        # Select only MSE from performance dictionary. Use ndarray.item method to catch errors in case MSE output is not a float.\r\n",
    "        mse_value = np.asarray([value for key, value in perf_dict.items() if key == \"MSE\"]).item()\r\n",
    "        \r\n",
    "        # Append MSE list.\r\n",
    "        mse_list.append(mse_value)\r\n",
    "\r\n",
    "        # Print model name, predictor list and MSE.\r\n",
    "        print(f\"This is DRF {name} model trained on {predictor_list} and its MSE is {mse_value:.2f}\")\r\n",
    "\r\n",
    "        # Add prediction to original H2O frame to help further analysis.\r\n",
    "        dataset_plus_prediction = frame.cbind(prediction)\r\n",
    "\r\n",
    "        # Convert H2O frame of model to pandas dataframe.\r\n",
    "        dataset_plus_prediction_pandas = dataset_plus_prediction.as_data_frame()\r\n",
    "\r\n",
    "        # Export prediction dataframe.\r\n",
    "        output_address = pred_output_folder + name\r\n",
    "        dataset_plus_prediction_pandas.to_csv(output_address + \".csv\", index=False)\r\n",
    "\r\n",
    "    # Zip names and MSE values into a pandas dataframe.\r\n",
    "    mse_models = pd.DataFrame(zip(model_names, mse_list), columns=[\"model_name\", \"mse\"])\r\n",
    "\r\n",
    "    # Export MSE dataframe to csv file.\r\n",
    "    mse_models.to_csv(mse_output_folder + \"drf_mse.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3.2 Gradient Boosting Machine - GBM."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write function to generate GBM model and export prediction as pandas dataframe.\r\n",
    "\r\n",
    "def model_h2o_gbm(frames, pred_output_folder, mse_output_folder):\r\n",
    "    \"\"\"Build GBM model in H2O for each dataset, add prediction to pandas dataframe, export result and MSE as csv.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    frames (dict): Dictionary containing frames, predictors and response column.\r\n",
    "    pred_output_folder (str): Path to folder where to export GBM model.\r\n",
    "    mse_output_folder (str): Path to folder where to export file with MSE of all GBM models.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    zip archive of each model\r\n",
    "    csv file with predictions of each model\r\n",
    "    csv file with MSE of all GBM models\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # Create list of model names.\r\n",
    "    model_names = []\r\n",
    "\r\n",
    "    # Create list of MSE results from each model.\r\n",
    "    mse_list = []\r\n",
    "\r\n",
    "    # Iterate through dictionary and store its elements under short variable names to help with readability:\r\n",
    "    for key, value in frames.items():\r\n",
    "        # Access the name.\r\n",
    "        name = str(key) + \"_gbm\"\r\n",
    "\r\n",
    "        # Append model name to list.\r\n",
    "        model_names.append(name)\r\n",
    "\r\n",
    "        # Access the frame.\r\n",
    "        frame = frames[key][\"frame\"]\r\n",
    "        # Access the predictors.\r\n",
    "        predictor_list = frames[key][\"predictors\"]\r\n",
    "        # Access the response.\r\n",
    "        response_column = frames[key][\"response\"]\r\n",
    "\r\n",
    "        # Split rows into training, validation and test sets. This makes reproducibility possible.\r\n",
    "        train = frame[frame[\"split\"]==\"train\"]\r\n",
    "        valid = frame[frame[\"split\"]==\"valid\"]\r\n",
    "        test = frame[frame[\"split\"]==\"test\"]\r\n",
    "\r\n",
    "        # Instantiate model with custom parameters.\r\n",
    "        model = H2OGradientBoostingEstimator(seed=12, categorical_encoding=\"Enum\", nfolds=4, fold_assignment=\"random\", \r\n",
    "        min_rows=1, nbins=13, nbins_top_level=16, distribution=\"gaussian\", build_tree_one_node=True)\r\n",
    "\r\n",
    "        # Train model. Specify predictors, response column, training frame and validation frame.\r\n",
    "        model.train(x=predictor_list, y=response_column, training_frame=train, validation_frame=valid, model_id=name+\"_model\")\r\n",
    "\r\n",
    "        # Print model to show variable importance.\r\n",
    "        # print(model)\r\n",
    "        \r\n",
    "        # Export model.\r\n",
    "        model_file = model.download_mojo(path=\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/models/gbm_models\", get_genmodel_jar=False)\r\n",
    "\r\n",
    "        # Generate prediction. It gets stored in a H2O frame with one column named \"predict\".\r\n",
    "        prediction = model.predict(frame)\r\n",
    "\r\n",
    "        # Calculate model performance on test set and print it.\r\n",
    "        performance = model.model_performance(test)\r\n",
    "\r\n",
    "        # Export model performance to json file.\r\n",
    "        perf_dict = performance._metric_json\r\n",
    "\r\n",
    "        # Select only MSE from performance json file. Use ndarray.item method to catch errors in case MSE output is not a float.\r\n",
    "        mse_value = np.asarray([value for key, value in perf_dict.items() if key == \"MSE\"]).item()\r\n",
    "        \r\n",
    "        # Append MSE list.\r\n",
    "        mse_list.append(mse_value)\r\n",
    "\r\n",
    "        # Print model name, predictor list and MSE.\r\n",
    "        print(f\"This is GBM {name} model trained on {predictor_list} and its MSE is {mse_value:.2f}.\")\r\n",
    "\r\n",
    "        # Add prediction to original H2O frame to help further analysis.\r\n",
    "        dataset_plus_prediction = frame.cbind(prediction)\r\n",
    "\r\n",
    "        # Convert H2O frame to pandas dataframe.\r\n",
    "        dataset_plus_prediction_pandas = dataset_plus_prediction.as_data_frame()\r\n",
    "\r\n",
    "        # Export prediction dataframe.\r\n",
    "        output_address = pred_output_folder + name + \".csv\"\r\n",
    "        dataset_plus_prediction_pandas.to_csv(output_address, index=False)\r\n",
    "\r\n",
    "    # Zip names and MSE values into a pandas dataframe.\r\n",
    "    mse_models = pd.DataFrame(zip(model_names, mse_list), columns=[\"model_name\", \"mse\"])\r\n",
    "\r\n",
    "    # Export MSE dataframe to csv file.\r\n",
    "    mse_models.to_csv(mse_output_folder + \"gbm_mse.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Output folders for pandas prediction dataframes resulted from DRF and GBM models.\r\n",
    "pred_drf_folder = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/models/drf_models/\"\r\n",
    "pred_gbm_folder = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/models/gbm_models/\"\r\n",
    "\r\n",
    "# Output folder for MSE of models.\r\n",
    "mse_folder = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/metrics/mse/\"\r\n",
    "\r\n",
    "# Call functions that build models and export dataframes. \r\n",
    "model_h2o_drf(frames_dictionary, pred_drf_folder, mse_folder)\r\n",
    "model_h2o_gbm(frames_dictionary, pred_gbm_folder, mse_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 5. EVALUATION"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 Evaluate results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Path to folder containing predictions.\r\n",
    "predictions_path = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/predictions/\"\r\n",
    "\r\n",
    "# Select files containing predictions. Recursive parameter extracts files also from subfolders in path.\r\n",
    "predictions_files = glob.glob(predictions_path + \"/**/*.csv\", recursive=True)\r\n",
    "\r\n",
    "# Extract name of files and use them to store dataframes.\r\n",
    "predictions_names = [PureWindowsPath(elem).stem for elem in predictions_files]\r\n",
    "\r\n",
    "# Read files into pandas dataframes.\r\n",
    "predictions_dataframes = [pd.read_csv(item) for item in predictions_files]\r\n",
    "\r\n",
    "# Create dictionary to store names and dataframes of predictions.\r\n",
    "predictions_dict = dict(zip(predictions_names, predictions_dataframes))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.1 Assessment of data mining results w.r.t. business success criteria."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create function to input dictionary of dataframes and return their recall scores.\r\n",
    "\r\n",
    "def recall_score(input_dict, real_response_column, predict_column, threshold, recall_output_folder):\r\n",
    "    \"\"\"Calculate recall score of predictions and export them to csv file.\r\n",
    "\r\n",
    "    The name of the response column should be the same in all dataframes. Same applies for predicted column.\r\n",
    "    Possible values of recall score are between 0 and 1.\r\n",
    "    The function returns \"np.NaN\" if the total number of true positives plus false negatives is zero.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    input_dict (dict): Dictionary of dataframes and their names.\r\n",
    "    real_response_column (str): The name of the response column with numerical data as values.\r\n",
    "    predict_column(str): The name of the predicted column with numerical data as values.\r\n",
    "    threshold (int, float): The threshold that separates outcomes.\r\n",
    "    recall_output_folder (str): Path to folder where to export csv file with recall scores.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    csv file with recall scores.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Create list of model names.\r\n",
    "    model_names = []\r\n",
    "\r\n",
    "    # Create list of recall scores from all models.\r\n",
    "    recall_list = []\r\n",
    "\r\n",
    "    # Iterate through input dictionary:\r\n",
    "    for key, value in input_dict.items():\r\n",
    "        # Access the name of the model.\r\n",
    "        model_name = str(key)\r\n",
    "\r\n",
    "        # Append name to model list.\r\n",
    "        model_names.append(model_name)\r\n",
    "\r\n",
    "        # Access the dataframe.\r\n",
    "        predictions_df = input_dict[key]\r\n",
    "\r\n",
    "        # Select true positives and false negatives:\r\n",
    "        tp = predictions_df[(predictions_df[real_response_column] < threshold) & (predictions_df[predict_column] < threshold)]\r\n",
    "        fn = predictions_df[(predictions_df[real_response_column] < threshold) & (predictions_df[predict_column] >= threshold)]\r\n",
    "\r\n",
    "        # Calculate recall score:\r\n",
    "        try:\r\n",
    "            recall = len(tp) / (len(tp) + len(fn))\r\n",
    "        except ZeroDivisionError:\r\n",
    "            recall = np.NaN\r\n",
    "        \r\n",
    "        # Append recall to score list.\r\n",
    "        recall_list.append(recall)\r\n",
    "\r\n",
    "    # Zip model names and recall scores into a pandas dataframe.\r\n",
    "    recall_models = pd.DataFrame(zip(model_names, recall_list), columns=[\"model_name\", \"recall\"])\r\n",
    "\r\n",
    "    # Export recall dataframe to csv file.\r\n",
    "    recall_models.to_csv(recall_output_folder + \"recall_score.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Folder where to store recall.\r\n",
    "recall_path = \"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/tree/main/beer_output/metrics/recall/\"\r\n",
    "\r\n",
    "# Generate recall scores.\r\n",
    "recall_score(predictions_dict, \"rating\", \"predict\", 5, recall_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import recall score file and MSE files of DRF and GBM models.\r\n",
    "drf_gbm_recall_score = pd.read_csv(\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_output/metrics/recall/recall_score.csv\")\r\n",
    "drf_mse = pd.read_csv(\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_output/metrics/mse/drf_mse.csv\")\r\n",
    "gbm_mse = pd.read_csv(\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_output/metrics/mse/gbm_mse.csv\")\r\n",
    "\r\n",
    "# Merge the MSE files.\r\n",
    "merged_mse = drf_mse.merge(gbm_mse, how=\"outer\")\r\n",
    "\r\n",
    "# Merge total MSE with recall score.\r\n",
    "mse_recall = merged_mse.merge(drf_gbm_recall_score, how=\"outer\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create column to store the model type.\r\n",
    "mse_recall[\"model_type\"] = mse_recall[\"model_name\"].str.contains(\"drf\")\r\n",
    "mse_recall[\"model_type\"] = mse_recall[\"model_type\"].replace({True: \"DRF\", False: \"GBM\"})\r\n",
    "\r\n",
    "# Create a column to store the range of each dataset.\r\n",
    "mse_recall[\"dataset_range\"] = mse_recall[\"model_name\"].str.contains(\"_2std\")\r\n",
    "mse_recall[\"dataset_range\"] = mse_recall[\"dataset_range\"].replace({True: \"2-std\", False: \"all\"})\r\n",
    "\r\n",
    "# Sort dataframe by recall score.\r\n",
    "mse_recall.sort_values([\"recall\", \"model_name\"], ascending=False, inplace=True)\r\n",
    "\r\n",
    "# Export dataframe.\r\n",
    "mse_recall.to_csv(\"https://github.com/alina-molnar/Beer-Recommendation-Project-Proof-of-Concept/blob/main/beer_output/metrics/mse_recall.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recall score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot MSE and the recall score of each model to compare metrics.\r\n",
    "fig, ax = plt.subplots()\r\n",
    "sns.lineplot(x=\"model_name\", y=\"mse\", data=mse_recall, label=\"MSE\", linestyle=\"dotted\", marker=\"o\")\r\n",
    "sns.lineplot(x=\"model_name\", y=\"recall\", data=mse_recall, label=\"Recall\", linestyle=\"dashed\", marker=\"D\")\r\n",
    "ax.set(title=\"MSE And Recall Score Of Models\", xlabel=\"\", ylabel=\"MSE and recall\")\r\n",
    "ax.set_xticks(np.arange(len(mse_recall[\"model_name\"])))\r\n",
    "plt.xticks(rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "ax.legend()\r\n",
    "plt.show()\r\n",
    "# MSE is lowest on models with maximum recall score, which is to be expected.\r\n",
    "# However, MSE doesn't show a reverse pattern of recall. This proves that lower MSE doesn't necessarily mean a better model."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.2 Approved Models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print MSE and recall dataframe.\r\n",
    "print(mse_recall)\r\n",
    "\r\n",
    "# Plot recall scores. Use dodge parameter to create even space between bars when using hue.\r\n",
    "# Graph split by model type.\r\n",
    "sns.barplot(x=\"model_name\", y=\"recall\", data=mse_recall, hue=mse_recall[\"model_type\"], dodge=False)\r\n",
    "plt.xticks(rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "plt.ylabel(mse_recall[\"recall\"].name.capitalize())\r\n",
    "plt.title(\"recall of models split by type\".title())\r\n",
    "plt.legend(loc=\"upper right\")\r\n",
    "plt.show()\r\n",
    "# Graph shows that DRF and GBM have the similar results for the same model, except for beer full range dataset where DRF performed better.\r\n",
    "# Will use DRF models for predictions on the unseen dataset.\r\n",
    "\r\n",
    "# Graph split by dataset range.\r\n",
    "sns.barplot(x=\"model_name\", y=\"recall\", data=mse_recall, hue=mse_recall[\"dataset_range\"], dodge=False)\r\n",
    "plt.xticks(rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\r\n",
    "plt.ylabel(mse_recall[\"recall\"].name.capitalize())\r\n",
    "plt.title(\"recall of models split by dataset range\".title())\r\n",
    "plt.legend(loc=\"upper right\")\r\n",
    "plt.show()\r\n",
    "# Graph shows that full range datasets generated better models than datasets with 2*std away ratings.\r\n",
    "# This was to be expected because the goal of the project is to predict outliers, not the bulk of average ratings.\r\n",
    "# Will keep outliers when testing the model on the unseen beer dataset."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Review Process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### False negatives."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create function to input dictionary of frames and return dictionary of false negatives in each model:\r\n",
    "\r\n",
    "def false_negatives_dictionary(input_dict, real_response_column, predict_column, threshold):\r\n",
    "    \"\"\"Select false negatives observations from model output dataframes.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    input_dict (dict): Dictionary of dataframes and their names.\r\n",
    "    real_response_column (str): The name of the response column containing numerical data as values.\r\n",
    "    predict_column(str): The name of the predicted column containing numerical data as values.\r\n",
    "    threshold (int, float): The threshold that separates outcomes.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    dict: Dictionary of dataframes with false negatives. Keys are names and values are pandas dataframes. \r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Create empty dictionary to be populated at each iteration:\r\n",
    "    fn_dict = {}\r\n",
    "\r\n",
    "    # Iterate through input dictionary to extract each dataframe and its name:\r\n",
    "    for key, value in input_dict.items():\r\n",
    "        dataframe_name = str(key)\r\n",
    "        \r\n",
    "        # Select rows that contain false negatives:\r\n",
    "        fn_dataframe = value[(value[real_response_column] < threshold) & (value[predict_column] >= threshold)]\r\n",
    "\r\n",
    "        # Update empty dictionary with each false negative dataframe and its name:\r\n",
    "        if not fn_dataframe.empty:\r\n",
    "            # Define name for each false negatives dataframe:\r\n",
    "            fn_name = dataframe_name + \"_fn\"\r\n",
    "            fn_dict[fn_name] = fn_dataframe\r\n",
    "        else:\r\n",
    "            pass\r\n",
    "    return fn_dict\r\n",
    "\r\n",
    "\r\n",
    "false_negatives = false_negatives_dictionary(predictions_dict, \"rating\", \"predict\", 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### False negatives split by occurence of observations in subgroups."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_occurrences(fn_dictionary):\r\n",
    "    \"\"\"Subplots of false negatives split by occurrence in each dataset.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    fn_dictionary (dict): Dictionary of dataframes and their names.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    Seaborn countplot in subplots of false negatives.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Create figure and set its title:\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.suptitle(\"Occurrence of observations in false negatives\".title())\r\n",
    "    # Start index of subplots:\r\n",
    "    i=0\r\n",
    "\r\n",
    "    # Iterate through input dictionary:\r\n",
    "    for key, value in fn_dictionary.items():\r\n",
    "        dataframe_name = str(key)\r\n",
    "\r\n",
    "        # Add subplots sequentially.\r\n",
    "        # Mark the first subplot as i+1 because subplot indices start at 1, and i is initialized at 0.\r\n",
    "        ax = fig.add_subplot(3, 4, i+1)\r\n",
    "        # Set title of subplot:\r\n",
    "        ax.set_title(f\"{dataframe_name}\", verticalalignment=\"top\", y=0.9)\r\n",
    "        \r\n",
    "        # Select rows of each subgroup:\r\n",
    "        too_few = value[value[\"occurrence\"] == \"too_few\"]\r\n",
    "        enough = value[value[\"occurrence\"] == \"enough\"]\r\n",
    "\r\n",
    "        # If both subgroups are present use whole dataframe for plotting, otherwise use the single series.\r\n",
    "        # This helps when aligning labels.\r\n",
    "        if len(too_few[\"occurrence\"]) > 0:\r\n",
    "            sns.countplot(x=\"occurrence\", data=value, order=value[\"occurrence\"].value_counts().index)\r\n",
    "        else:\r\n",
    "            sns.countplot(x=\"occurrence\", data=enough)\r\n",
    "\r\n",
    "        # Count bars to be plotted because it helps with setting bar width:\r\n",
    "        bar_number = value[\"occurrence\"].nunique()\r\n",
    "\r\n",
    "        # Set bar width. Matplotlib divides the plot area into bars according to the number of bars. \r\n",
    "        # The float parameter provided by user is not used as a constant.\r\n",
    "        # That's why setting a parameter dependent on number of bars cancels the division made by matplotlib.\r\n",
    "        # This results in bars with the same width.\r\n",
    "        for patch in ax.patches:\r\n",
    "            patch.set_width(0.3*bar_number)\r\n",
    "        # Show value counts of observations as labels on top of bars:\r\n",
    "        ax.bar_label(ax.containers[0])\r\n",
    "\r\n",
    "        # Set only y label to show they are counts.\r\n",
    "        # An x label would crowd the figure because of limited space between rows of graphs.\r\n",
    "        # The title of the whole figure already says what's on x axis.\r\n",
    "        ax.set(xlabel=\"\", ylabel=\"Count\")\r\n",
    "\r\n",
    "        # Calculate middle points of bars and use them to mark location of x-ticks:\r\n",
    "        midpoints = [patch.get_x() + patch.get_width() / 2 for patch in ax.patches]\r\n",
    "        ax.set_xticks(midpoints)\r\n",
    "        # Define list of labels and set them under x-ticks:\r\n",
    "        list_labels = list(value[\"occurrence\"].value_counts().index)\r\n",
    "        ax.set_xticklabels(list_labels)\r\n",
    "\r\n",
    "        # Set common y limit for all subplots in order to have the same scale when visualizing them:\r\n",
    "        plt.ylim([0, 20])\r\n",
    "\r\n",
    "        # Increment the index for the next subplot:\r\n",
    "        i += 1\r\n",
    "    \r\n",
    "    # Show all graphs in one figure.\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "plot_occurrences(false_negatives)\r\n",
    "\r\n",
    "# Graphs show that most of the wrong predictions were generated for subgroups that had enough observations."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.1 Import and clean unseen file following the same steps as with seen data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import unseen file.\r\n",
    "beer_unseen_raw = pd.read_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_input\\\\beer_unseen_raw.csv\", header=0)\r\n",
    "\r\n",
    "# Standardize appeareance. Convert column labels to lowercase.\r\n",
    "beer_unseen_raw.columns = beer_unseen_raw.columns.str.lower()\r\n",
    "\r\n",
    "# Convert columns values to lowercase if they are strings.\r\n",
    "beer_unseen = beer_unseen_raw.applymap(lambda col:col.lower() if type(col) == str else col)\r\n",
    "\r\n",
    "# Convert Name column from object to string.\r\n",
    "beer_unseen[\"name\"] = beer_unseen[\"name\"].astype(\"string\")\r\n",
    "\r\n",
    "# Cut alcohol content from end of name and store as separate column.\r\n",
    "beer_unseen[\"abv\"] = [name.rsplit(maxsplit=1)[-1] for name in beer_unseen[\"name\"]]\r\n",
    "\r\n",
    "# Convert alcohol content to float.\r\n",
    "beer_unseen[\"abv\"] = beer_unseen[\"abv\"].astype(float)\r\n",
    "\r\n",
    "# Validation of uniqueness in beer names. Check for duplicates, remove if found.\r\n",
    "beer_unseen.drop_duplicates(subset=\"name\", keep=\"last\", inplace=True)\r\n",
    "\r\n",
    "# Create column for Pasteurization status.\r\n",
    "beer_unseen[\"pasteurization\"] = beer_unseen[\"name\"].str.contains(\"|\".join(unpasteurized_words))\r\n",
    "beer_unseen[\"pasteurization\"] = beer_unseen[\"pasteurization\"].replace({True: \"unpasteurized\", False: \"pasteurized\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.2 Create datasets based on alcohol content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split unseen dataset into alcohol-free, light and regular beer.\r\n",
    "alc_free_unseen = beer_unseen[beer_unseen[\"abv\"] <= 0.5]\r\n",
    "light_unseen = beer_unseen[(beer_unseen[\"abv\"] > 0.5) & (beer_unseen[\"abv\"] <= 3)]\r\n",
    "regular_unseen = beer_unseen[beer_unseen[\"abv\"] > 3]\r\n",
    "\r\n",
    "# Create list of unseen datasets, list of identificators and zip them.\r\n",
    "clean_unseen = [alc_free_unseen, light_unseen, regular_unseen]\r\n",
    "unseen_names = [\"alc_free_unseen\", \"light_unseen\", \"regular_unseen\"]\r\n",
    "unseen_dict = dict(zip(unseen_names, clean_unseen))\r\n",
    "\r\n",
    "# Export unseen datasets after cleaning.\r\n",
    "unseen_clean_path = \"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_clean\\\\\"\r\n",
    "export_files_csv(unseen_dict, unseen_clean_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.3 Apply ML models on unseen data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Start H2O and import unseen files.\r\n",
    "h2o.init(nthreads=-1, enable_assertions=False)\r\n",
    "alc_free_unseen_frame = h2o.import_file(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_clean\\\\alc_free_unseen.csv\")\r\n",
    "light_unseen_frame = h2o.import_file(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_clean\\\\light_unseen.csv\")\r\n",
    "regular_unseen_frame = h2o.import_file(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_clean\\\\regular_unseen.csv\")\r\n",
    "\r\n",
    "# Import models trained models in step 4.3.3.\r\n",
    "alc_free_imported_model = h2o.import_mojo(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\beer_output\\\\models\\\\drf_models\\\\alc_free_all_drf_model.zip\")\r\n",
    "light_imported_model = h2o.import_mojo(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\beer_output\\\\models\\\\drf_models\\\\light_all_drf_model.zip\")\r\n",
    "regular_imported_model = h2o.import_mojo(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\beer_output\\\\models\\\\drf_models\\\\regular_all_drf_model.zip\")\r\n",
    "\r\n",
    "# Select test rows\r\n",
    "alc_free_unseen_test = alc_free_unseen_frame[alc_free_unseen_frame[\"split\"]==\"test\"]\r\n",
    "light_unseen_test = light_unseen_frame[light_unseen_frame[\"split\"]==\"test\"]\r\n",
    "regular_unseen_test = regular_unseen_frame[regular_unseen_frame[\"split\"]==\"test\"]\r\n",
    "\r\n",
    "# Generate predictions\r\n",
    "alc_free_unseen_prediction = alc_free_imported_model.predict(alc_free_unseen_frame)\r\n",
    "light_unseen_prediction = light_imported_model.predict(light_unseen_frame)\r\n",
    "regular_unseen_prediction = regular_imported_model.predict(regular_unseen_frame)\r\n",
    "\r\n",
    "# Calculate performance of model on test rows\r\n",
    "alc_free_unseen_perf = alc_free_imported_model.model_performance(alc_free_unseen_test)\r\n",
    "light_unseen_perf = light_imported_model.model_performance(light_unseen_test)\r\n",
    "regular_unseen_perf = regular_imported_model.model_performance(regular_unseen_test)\r\n",
    "\r\n",
    "# Store model performance as json into a dictionary.\r\n",
    "alc_free_perf_dict = alc_free_unseen_perf._metric_json\r\n",
    "light_perf_dict = light_unseen_perf._metric_json\r\n",
    "regular_perf_dict = regular_unseen_perf._metric_json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.4 Export predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Frames plus predictions\r\n",
    "alc_free_unseen_plus_pred = alc_free_unseen_frame.cbind(alc_free_unseen_prediction)\r\n",
    "light_unseen_plus_pred = light_unseen_frame.cbind(light_unseen_prediction)\r\n",
    "regular_unseen_plus_pred = regular_unseen_frame.cbind(regular_unseen_prediction)\r\n",
    "\r\n",
    "# Convert frames to dataframes\r\n",
    "alc_free_unseen_pred_df = alc_free_unseen_plus_pred.as_data_frame()\r\n",
    "light_unseen_pred_df = light_unseen_plus_pred.as_data_frame()\r\n",
    "regular_unseen_pred_df = regular_unseen_plus_pred.as_data_frame()\r\n",
    "\r\n",
    "# Create list of unseen predictions ad zip them with dataset identificators.\r\n",
    "unseen_predictions = [alc_free_unseen_pred_df, light_unseen_pred_df, regular_unseen_pred_df]\r\n",
    "unseen_predictions_dict = dict(zip(unseen_names, unseen_predictions))\r\n",
    "\r\n",
    "# Export prediction dataframe.\r\n",
    "alc_free_unseen_pred_df.to_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_predictions\\\\alc_free_unseen_pred.csv\", index=False)\r\n",
    "light_unseen_pred_df.to_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_predictions\\\\light_unseen_pred.csv\", index=False)\r\n",
    "regular_unseen_pred_df.to_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_predictions\\\\regular_unseen_pred.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.5 Calculate recall"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write function to calculate and export recall scores.\r\n",
    "\r\n",
    "def calculate_recall(dict_of_predictions):\r\n",
    "    \"\"\"Calculate recall score of predictions and export them to csv file.\r\n",
    "\r\n",
    "    Possible values of recall score are between 0 and 1.\r\n",
    "    The function returns \"np.NaN\" if the total number of true positives plus false negatives is zero.\r\n",
    "\r\n",
    "    Args:\r\n",
    "    dict_of_predictions (dict): Dictionary of dataframes and their names.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    csv file with recall scores.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    recall_list = []\r\n",
    "    for key, value in dict_of_predictions.items():\r\n",
    "        name = str(key)\r\n",
    "\r\n",
    "        tp = value[(value[\"rating\"] < 5) & (value[\"predict\"] < 5)]\r\n",
    "        fn = value[(value[\"rating\"] < 5) & (value[\"predict\"] >= 5)]\r\n",
    "        \r\n",
    "        # Export fn dataframe.\r\n",
    "        fn.to_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_false_negatives\\\\\" + name + \".csv\", index=False)\r\n",
    "\r\n",
    "        # Calculate recall score:\r\n",
    "        try:\r\n",
    "            recall = len(tp) / (len(tp) + len(fn))\r\n",
    "        except ZeroDivisionError:\r\n",
    "            recall = np.NaN\r\n",
    "        \r\n",
    "        # Append recall to score list.\r\n",
    "        recall_list.append(recall)\r\n",
    "        \r\n",
    "    # Zip unseen names and recall scores into a pandas dataframe.\r\n",
    "    recall_df = pd.DataFrame(zip(unseen_names, recall_list), columns=[\"model_name\", \"recall\"])\r\n",
    "\r\n",
    "    # Export recall dataframe to csv file.\r\n",
    "    recall_df.to_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_metrics\\\\recall_unseen.csv\", index=False)\r\n",
    "\r\n",
    "calculate_recall(unseen_predictions_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1.6 Evaluate results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import recall file of unseen datasets.\r\n",
    "recall_unseen = pd.read_csv(\"C:\\\\Users\\\\alina\\\\OneDrive\\\\beer_project\\\\unseen_data\\\\unseen_output\\\\unseen_metrics\\\\recall_unseen.csv\")\r\n",
    "\r\n",
    "# Sort recall dataframe by score.\r\n",
    "recall_unseen.sort_values(\"recall\", ascending=False, inplace=True )\r\n",
    "\r\n",
    "# Print recall dataframe.\r\n",
    "print(recall_unseen)\r\n",
    "\r\n",
    "\r\n",
    "# Plot recall scores.\r\n",
    "sns.barplot(x=\"model_name\", y=\"recall\", data=recall_unseen)\r\n",
    "plt.title(\"recall of models split by type\".title())\r\n",
    "plt.ylabel(\"Recall\")\r\n",
    "plt.ylim([0, 1])\r\n",
    "plt.legend(loc=\"upper right\")\r\n",
    "plt.show()\r\n",
    "# Graph shows that regular beer is the only one from which low rated beer was detected.\r\n",
    "# Alcohol-free and light beers either had a scoze of 0, or didn't have low rated beer in the dataset.\r\n",
    "# It's possible to improve these scores or lack of score by collecting more data."
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}